{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#croping the image\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "image = cv2.imread('tss.jpg')\n",
    "y=0\n",
    "x=0\n",
    "h=32\n",
    "w=32\n",
    "crop = image[y:y+h, x:x+w]\n",
    "cv2.imshow('Image', crop)\n",
    "cv2.imwrite(\"Space.jpg\",crop)\n",
    "cv2.waitKey(0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image segmentation using otsu's binarization.\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from matplotlib import pyplot as plt\n",
    "img = cv.imread('coin.jpg')\n",
    "gray = cv.cvtColor(img,cv.COLOR_BGR2GRAY)\n",
    "#Otsu's binarization.\n",
    "ret, thresh = cv.threshold(gray,0,255,cv.THRESH_BINARY_INV+cv.THRESH_OTSU)\n",
    "# noise removal\n",
    "kernel = np.ones((3,3),np.uint8)\n",
    "opening = cv.morphologyEx(thresh,cv.MORPH_OPEN,kernel, iterations = 2)\n",
    "# sure background area\n",
    "sure_bg = cv.dilate(opening,kernel,iterations=3)\n",
    "# Finding sure foreground area\n",
    "dist_transform = cv.distanceTransform(opening,cv.DIST_L2,5)\n",
    "ret, sure_fg = cv.threshold(dist_transform,0.7*dist_transform.max(),255,0)\n",
    "# Finding unknown region\n",
    "sure_fg = np.uint8(sure_fg)\n",
    "unknown = cv.subtract(sure_bg,sure_fg)\n",
    "# Marker labelling\n",
    "ret, markers = cv.connectedComponents(sure_fg)\n",
    "# Add one to all labels so that sure background is not 0, but 1\n",
    "markers = markers+1\n",
    "# Now, mark the region of unknown with zero\n",
    "markers[unknown==255] = 0\n",
    "markers = cv.watershed(img,markers)\n",
    "img[markers == -1] = [255,0,0]\n",
    "    \n",
    "\n",
    "plt.imshow(markers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Background subtraction from video\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "cap = cv2.VideoCapture('vid.mp4')\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(3,3))\n",
    "fgbg = cv2.bgsegm.createBackgroundSubtractorGMG()\n",
    "while(1):\n",
    "    ret, frame = cap.read()\n",
    "    fgmask = fgbg.apply(frame)\n",
    "    fgmask = cv2.morphologyEx(fgmask, cv2.MORPH_OPEN, kernel)\n",
    "    cv2.imshow('frame',fgmask)\n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Background subtraction\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "cap = cv2.imread('tss.jpg')\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(3,3))\n",
    "fgbg = cv2.bgsegm.createBackgroundSubtractorGMG()\n",
    "# while(1):\n",
    "#     ret, frame = cap.read()\n",
    "fgmask = fgbg.apply(cap)\n",
    "fgmask = cv2.morphologyEx(cap, cv2.MORPH_OPEN, kernel)\n",
    "cv2.imshow('frame',fgmask)\n",
    "k = cv2.waitKey(30) & 0xff\n",
    "\n",
    "# cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##vertical and horizontal line detection\n",
    "\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "src = cv.imread('ha.jpg', cv.IMREAD_COLOR)\n",
    "cv.imshow(\"src\", src)\n",
    "\n",
    "gray = cv.cvtColor(src, cv.COLOR_BGR2GRAY)\n",
    "# cv.imshow(\"gray\", gray)\n",
    "# Apply adaptiveThreshold at the bitwise_not of gray, notice the ~ symbol\n",
    "gray = cv.bitwise_not(gray)\n",
    "bw = cv.adaptiveThreshold(gray, 255, cv.ADAPTIVE_THRESH_MEAN_C, \\\n",
    "                            cv.THRESH_BINARY, 15, -2)\n",
    "# Show binary image\n",
    "cv.imshow(\"binary\", bw)\n",
    "\n",
    "# Create the images that will use to extract the horizontal and vertical lines\n",
    "horizontal = np.copy(bw)\n",
    "vertical = np.copy(bw)\n",
    " # Specify size on horizontal axis\n",
    "cols = horizontal.shape[1]\n",
    "horizontal_size = cols // 30\n",
    "# Create structure element for extracting horizontal lines through morphology operations\n",
    "horizontalStructure = cv.getStructuringElement(cv.MORPH_RECT, (horizontal_size, 1))\n",
    "# Apply morphology operations\n",
    "horizontal = cv.erode(horizontal, horizontalStructure)\n",
    "horizontal = cv.dilate(horizontal, horizontalStructure)\n",
    "# Show extracted horizontal lines\n",
    "cv.imshow(\"horizontal\", horizontal)\n",
    "#  # Specify size on vertical axis\n",
    "rows = vertical.shape[0]\n",
    "verticalsize = rows // 20\n",
    "# # Create structure element for extracting vertical lines through morphology operations\n",
    "verticalStructure = cv.getStructuringElement(cv.MORPH_RECT, (1, verticalsize))\n",
    "# # Apply morphology operations\n",
    "vertical = cv.erode(vertical, verticalStructure)\n",
    "vertical = cv.dilate(vertical, verticalStructure)\n",
    "# # Show extracted vertical lines\n",
    "cv.imshow(\"vertical\", vertical)\n",
    "cv.waitKey(0) \n",
    "# print(horizontalStructure)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82\n",
      "[[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "  1 1 1 1 1]]\n",
      "[[255 255 255 ... 255 255 255]\n",
      " [255 255 255 ... 255 255 255]\n",
      " [255 255 255 ... 255 255 255]\n",
      " ...\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [255 255 255 ... 255 255 255]]\n",
      "image\n",
      "[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0]]\n",
      "82\n"
     ]
    }
   ],
   "source": [
    "### horizontal projection using \n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "src = cv.imread('best/104.jpg', cv.IMREAD_COLOR)\n",
    "cv.imshow(\"src\", src)\n",
    "\n",
    "gray = cv.cvtColor(src, cv.COLOR_BGR2GRAY)\n",
    "cv.imshow(\"gray\", gray)\n",
    "# Apply adaptiveThreshold at the bitwise_not of gray, notice the ~ symbol\n",
    "gray = cv.bitwise_not(gray)\n",
    "bw = cv.adaptiveThreshold(gray, 255, cv.ADAPTIVE_THRESH_MEAN_C, \\\n",
    "                            cv.THRESH_BINARY, 15, -2)\n",
    "# Show binary image\n",
    "cv.imshow(\"binary\", bw)\n",
    "\n",
    "# Create the images that will use to extract the horizontal and vertical lines\n",
    "horizontal = np.copy(bw)\n",
    "vertical = np.copy(bw)\n",
    " # Specify size on horizontal axis\n",
    "cols = horizontal.shape[1]\n",
    "horizontal_size = cols // 2\n",
    "# Create structure element for extracting horizontal lines through morphology operations\n",
    "horizontalStructure = cv.getStructuringElement(cv.MORPH_RECT, (horizontal_size, 1))\n",
    "\n",
    "# Apply morphology operations\n",
    "horizontal1 = cv.erode(horizontal, horizontalStructure)\n",
    "horizontal1 = cv.dilate(horizontal1, horizontalStructure)\n",
    "\n",
    "# Show extracted horizontal lines\n",
    "cv.imshow(\"horizontal\", horizontal1)\n",
    "## removing the line form character\n",
    "filled_black=horizontal-horizontal1\n",
    "cv.imshow('filled',filled_black)\n",
    "print(cols)\n",
    "print(horizontalStructure)\n",
    "print(horizontal1)\n",
    "print('image')\n",
    "print(horizontalStructure-1)\n",
    "print(cols)\n",
    "cv.waitKey(0) \n",
    "\n",
    "# cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##horizontal line cancellation using bitwise_ method\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread(\"c.jpg\", 0)\n",
    "\n",
    "if len(img.shape) != 2:\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "else:\n",
    "    gray = img\n",
    "\n",
    "gray = cv2.bitwise_not(gray)\n",
    "bw = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C, \n",
    "cv2.THRESH_BINARY, 15, -2)\n",
    "\n",
    "horizontal = np.copy(bw)\n",
    "\n",
    "cols = horizontal.shape[1]\n",
    "horizontal_size = cols // 20\n",
    "\n",
    "horizontalStructure = cv2.getStructuringElement(cv2.MORPH_RECT, (horizontal_size, 1))\n",
    "\n",
    "horizontal = cv2.erode(horizontal, horizontalStructure)\n",
    "horizontal = cv2.dilate(horizontal, horizontalStructure)\n",
    "\n",
    "cv2.imwrite(\"horizontal_lines_extracted.png\", horizontal)\n",
    "\n",
    "horizontal_inv = cv2.bitwise_not(horizontal)\n",
    "cv2.imwrite(\"inverse_extracted.png\", horizontal_inv)\n",
    "\n",
    "masked_img = cv2.bitwise_and(gray, gray, mask=horizontal_inv)\n",
    "masked_img_inv = cv2.bitwise_not(masked_img)\n",
    "\n",
    "cv2.imwrite(\"masked_img.jpg\", masked_img_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "49\n",
      "101\n",
      "50\n",
      "101\n",
      "50\n",
      "101\n",
      "50\n",
      "102\n",
      "51\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1524e4e85c8>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Croping the selected character\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "img_rgb = cv2.imread('sob.jpg')\n",
    "img_gray = cv2.cvtColor(img_rgb, cv2.COLOR_BGR2GRAY)\n",
    "template = cv2.imread('ta.jpg',0)\n",
    "w, h = template.shape[::-1]\n",
    "\n",
    "res = cv2.matchTemplate(img_gray,template,cv2.TM_CCOEFF_NORMED)\n",
    "threshold = 0.8\n",
    "loc = np.where( res >= threshold)\n",
    "for pt in zip(*loc[::-1]):\n",
    "    cv2.rectangle(img_rgb, pt, (pt[0] + w, pt[1] + h), (255,0,0), 1)\n",
    "    print(pt[1] + h)  ##upper limt of height\n",
    "    print(pt[1])      ##lowre limit of height\n",
    "img_rgb=img_rgb[pt[1]:pt[1] + h,pt[0]:pt[0] + w]\n",
    "cv2.imwrite('res.png',img_rgb)\n",
    "plt.imshow(img_rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## segmentation of image\n",
    "import cv2\n",
    "import numpy as np\n",
    "#read image\n",
    "img = cv2.imread('c.jpg')\n",
    "\n",
    "#grayscale\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "#binarize \n",
    "ret,thresh = cv2.threshold(gray,127,255,cv2.THRESH_BINARY_INV)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "\n",
    "#find contours\n",
    "ctrs, new__ = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, \n",
    "cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "#sort contours\n",
    "sorted_ctrs = sorted(ctrs, key=lambda ctr: cv2.boundingRect(ctr)[0])\n",
    "\n",
    "for i, ctr in enumerate(sorted_ctrs):\n",
    "    # Get bounding box\n",
    "    x, y, w, h = cv2.boundingRect(ctr)\n",
    "\n",
    "    # Getting ROI\n",
    "#     roi = img[y:y+h, x:x+w]\n",
    "\n",
    "    # show ROI\n",
    "    #cv2.imwrite('roi_imgs.png', roi)\n",
    "#     cv2.imshow('charachter'+str(i), roi)\n",
    "    cv2.rectangle(img,(x,y),( x + w, y + h ),(90,0,255),2)\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "cv2.imshow('marked areas',img)\n",
    "cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[255 255 255 ... 255 255 255]\n",
      " [255 255 255 ... 255 255 255]\n",
      " [255 255 255 ... 255 255 255]\n",
      " ...\n",
      " [  0   0   0 ... 255 255 255]\n",
      " [  0   0   0 ... 255 255 255]\n",
      " [  0   0   0 ... 255 255 255]]\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "45\n",
      "jak 87\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "33\n",
      "jak 121\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "30\n",
      "jak 161\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "203\n",
      "this 203\n"
     ]
    }
   ],
   "source": [
    "##Horizontal Image segmentaion using projection method\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load as greyscale\n",
    "im = cv2.imread('e.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "(thresh, im) = cv2.threshold(im, 128, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "print(im)\n",
    "# Invert\n",
    "# im = 255 - im\n",
    "countp=0\n",
    "# countt=0\n",
    "countn=0\n",
    "xp=0\n",
    "lower_y=0\n",
    "crop=0\n",
    "# Calculate horizontal projection\n",
    "proj = np.sum(im,1)\n",
    "\n",
    "# Create output image same height as text, 500 px wide\n",
    "# m = np.max(proj)\n",
    "# w = 500\n",
    "result = np.zeros((proj.shape[0],500))\n",
    "\n",
    "# Draw a line for each row\n",
    "# for row in range(im.shape[0]):\n",
    "#     cv2.line(result, (0,row), (int(proj[row]*w/m),row), (255,255,255), 1)\n",
    "\n",
    "# print(proj)\n",
    "for i in proj:\n",
    "    countp+=1\n",
    "\n",
    "    if i>(np.max(proj)-500):\n",
    "        lower_y=countp\n",
    "        cv2.line(im, (0, countp), (im[1].size, countp), (0,255,0), 2)\n",
    "        cv2.imwrite('result.png', im)\n",
    "#         countt=1\n",
    "        countn=1\n",
    "    print(lower_y-xp)\n",
    "    if (lower_y-xp)>1:\n",
    "        print(\"jak\",lower_y)\n",
    "        crop=im[xp-1:lower_y,0:im[1].size]\n",
    "        cv2.imwrite('test/'+str(i)+'.jpg',crop)\n",
    "\n",
    "    if countn!=0:\n",
    "        xp=countp\n",
    "        yp=400\n",
    "        countn=0\n",
    "\n",
    "print(xp)\n",
    "print('this',lower_y)\n",
    "    \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "# Save result\n",
    "\n",
    "# print(crop)\n",
    "# print(np.max(proj))\n",
    "# print(im.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " ...\n",
      " [255 255 255 ... 255 255 255]\n",
      " [255 255 255 ... 255 255 255]\n",
      " [  0   0   0 ...   0   0   0]]\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "76\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "62\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "53\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "6\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "408\n",
      "this 408\n"
     ]
    }
   ],
   "source": [
    "## Vertical Image segmentaion using projection method\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load as greyscale\n",
    "im = cv2.imread('test/103785.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "(thresh, im) = cv2.threshold(im, 128, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "print(im)\n",
    "# Invert\n",
    "# im = 255 - im\n",
    "countp=0\n",
    "# countt=0\n",
    "countn=0\n",
    "xp=0\n",
    "lower_y=0\n",
    "crop=0\n",
    "# Calculate vertical projection\n",
    "proj = np.sum(im,0)\n",
    "#Calculating \n",
    "height,width=im.shape\n",
    "# Create output image same height as text, 500 px wide\n",
    "# m = np.max(proj)\n",
    "# w = 500\n",
    "result = np.zeros((proj.shape[0],500))\n",
    "\n",
    "# Draw a line for each row\n",
    "# for row in range(im.shape[0]):\n",
    "#     cv2.line(result, (0,row), (int(proj[row]*w/m),row), (255,255,255), 1)\n",
    "\n",
    "# print(proj)\n",
    "for i in proj:\n",
    "    countp+=1\n",
    "\n",
    "    if i>(np.max(proj)-5):\n",
    "        lower_y=countp\n",
    "        cv2.line(im, (countp,0), (countp,height), (0,255,0), 2)  ##border line draw just for simplification of croping\n",
    "        cv2.imwrite('result.png', im)\n",
    "        countn=1\n",
    "    print(lower_y-xp)\n",
    "    if (lower_y-xp)>1:\n",
    "        crop=im[0:height,xp-3:lower_y+3]\n",
    "        cv2.imwrite('best/'+str(countp)+'.jpg',crop)\n",
    "\n",
    "    if countn!=0:\n",
    "        xp=countp\n",
    "        countn=0\n",
    "\n",
    "print(countp)\n",
    "print('this',lower_y)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first\n",
      "first\n",
      "krishna\n",
      "hjkhjk\n",
      "hjkhjk\n",
      "hjkhjk\n",
      "hjkhjk\n",
      "krishna\n",
      "krishna\n",
      "hjkhjk\n",
      "hjkhjk\n",
      "hjkhjk\n",
      "first\n"
     ]
    }
   ],
   "source": [
    "##Horizontal Image segmentaion using projection method\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load as greyscale\n",
    "im = cv2.imread('test_img/o.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "# space=cv2.imread('Space.jpg')\n",
    "(thresh, im) = cv2.threshold(im, 128, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "countp=0\n",
    "countn=0\n",
    "xp=0\n",
    "lower_y=0\n",
    "crop=0\n",
    "croped_image_label=0\n",
    "# Calculate horizontal projection\n",
    "proj = np.sum(im,1)\n",
    "\n",
    "for i in proj:\n",
    "    countp+=1\n",
    "    if i>(np.max(proj)-500):\n",
    "        lower_y=countp\n",
    "        countn=1\n",
    "\n",
    "    if (lower_y-xp)>1:\n",
    "        crop=im[xp-4:lower_y+3,0:im[1].size]\n",
    "        print(\"first\")\n",
    "\n",
    "\n",
    "        ## Vertical Image segmentaion using projection method\n",
    "        countp1=0\n",
    "        countn1=0\n",
    "        xp1=0\n",
    "        lower_y1=0\n",
    "        crop1=0\n",
    "        # Calculate vertical projection\n",
    "        proj1 = np.sum(crop,0)\n",
    "        #Calculating \n",
    "        height,width=crop.shape\n",
    "        for j in proj1:\n",
    "            countp1+=1\n",
    "\n",
    "            if j>(np.max(proj1)-5):\n",
    "                lower_y1=countp1\n",
    "                countn1=1\n",
    "            if (lower_y1-xp1)>1:\n",
    "                crop1=crop[0:height,xp1-3:lower_y1+3]\n",
    "                crop1_copy=np.copy(crop1)\n",
    "                count=0\n",
    "                hori_black_sum=np.sum(crop1,1)\n",
    "                for k in hori_black_sum:\n",
    "                    min_acc=k<(np.min(hori_black_sum)+900)\n",
    "                    max_acc=k<(np.max(hori_black_sum)-900)\n",
    "                    count+=1\n",
    "                    if min_acc&max_acc:\n",
    "                        cv2.line(crop1, (0,count), (crop1[1].size,count), (255,0,0), 2)\n",
    "                        \n",
    "                        print(\"krishna\")\n",
    "                        \n",
    "\n",
    "#                 cv2.imwrite('character.jpg',crop1)\n",
    "                ## segmentation of image\n",
    "                \n",
    "                #grayscale\n",
    "#                 gray = cv2.cvtColor(crop1,cv2.COLOR_BGR2GRAY)\n",
    "#                 cv2.waitKey(0)\n",
    "\n",
    "                #binarize \n",
    "                ret,thresh = cv2.threshold(crop1,127,255,cv2.THRESH_BINARY_INV)\n",
    "\n",
    "#                 cv2.waitKey(0)\n",
    "\n",
    "                #find contours\n",
    "                ctrs, new__ = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, \n",
    "                cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "                #sort contours\n",
    "                sorted_ctrs = sorted(ctrs, key=lambda ctr: cv2.boundingRect(ctr)[0])\n",
    "\n",
    "                for n, ctr in enumerate(sorted_ctrs):\n",
    "                    # Get bounding box\n",
    "                    x, y, w, h = cv2.boundingRect(ctr)\n",
    "\n",
    "                    if h>8:\n",
    "                        croped_image_label+=1\n",
    "                        character=crop1_copy[y-4:y+h+2,x-3:x+w+3]\n",
    "                        resized_char = cv2.resize(character, (32,32), interpolation = cv2.INTER_AREA)\n",
    "                        resized_char=255-resized_char\n",
    "                        cv2.imwrite('character/'+str(croped_image_label)+'.jpg',resized_char)\n",
    "                        cv2.waitKey(0)\n",
    "                        print(\"hjkhjk\")\n",
    "                \n",
    "                cv2.waitKey(0)\n",
    "                \n",
    "                croped_image_label+=1\n",
    "#                 cv2.imwrite('character/'+str(croped_image_label)+'.jpg',space)\n",
    "\n",
    "                \n",
    "######\n",
    "            if countn1!=0:\n",
    "                xp1=countp1\n",
    "                countn1=0\n",
    "\n",
    "    if countn!=0:\n",
    "        xp=countp\n",
    "        countn=0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first\n",
      "krishna\n",
      "krishna\n",
      "hjkhjk\n",
      "hjkhjk\n",
      "krishna\n",
      "krishna\n",
      "krishna\n",
      "hjkhjk\n",
      "hjkhjk\n",
      "krishna\n",
      "krishna\n",
      "hjkhjk\n"
     ]
    }
   ],
   "source": [
    "##Horizontal Image segmentaion using projection method\n",
    "################TEST OF ABOVE CODE AND modification\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load as greyscale\n",
    "im = cv2.imread('test_img/s.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "# space=cv2.imread('Space.jpg')\n",
    "(thresh, im) = cv2.threshold(im, 128, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "countp=0\n",
    "countn=0\n",
    "xp=0\n",
    "lower_y=0\n",
    "crop=0\n",
    "croped_image_label=0\n",
    "# Calculate horizontal projection\n",
    "proj = np.sum(im,1)\n",
    "\n",
    "for i in proj:\n",
    "    countp+=1\n",
    "    if i>(np.max(proj)-500):\n",
    "        lower_y=countp\n",
    "        countn=1\n",
    "\n",
    "    if (lower_y-xp)>2:\n",
    "        crop=im[xp-7:lower_y+3,0:im[1].size]\n",
    "        print(\"first\")\n",
    "\n",
    "\n",
    "        ## Vertical Image segmentaion using projection method\n",
    "        countp1=0\n",
    "        countn1=0\n",
    "        xp1=0\n",
    "        lower_y1=0\n",
    "        crop1=0\n",
    "        # Calculate vertical projection\n",
    "        proj1 = np.sum(crop,0)\n",
    "#         print(proj1)\n",
    "        #Calculating \n",
    "        height,width=crop.shape\n",
    "        for j in proj1:\n",
    "            countp1+=1\n",
    "\n",
    "            if j>(np.max(proj1)-5):\n",
    "                lower_y1=countp1\n",
    "                countn1=1\n",
    "            if (lower_y1-xp1)>1:\n",
    "                crop1=crop[0:height,xp1-3:lower_y1+3]\n",
    "                crop1_copy=np.copy(crop1)\n",
    "                count=0\n",
    "                hori_black_sum=np.sum(crop1,1)\n",
    "                for k in hori_black_sum:\n",
    "                    min_acc=k<(np.min(hori_black_sum)+900)\n",
    "                    max_acc=k<(np.max(hori_black_sum)-900)\n",
    "                    count+=1\n",
    "                    if min_acc&max_acc:\n",
    "                        cv2.line(crop1, (0,count), (crop1[1].size,count), (255,0,0), 2)\n",
    "                        \n",
    "                        print(\"krishna\")\n",
    "                        \n",
    "\n",
    "#                 cv2.imwrite('character.jpg',crop1)\n",
    "                ## segmentation of image\n",
    "                \n",
    "                #grayscale\n",
    "#                 gray = cv2.cvtColor(crop1,cv2.COLOR_BGR2GRAY)\n",
    "#                 cv2.waitKey(0)\n",
    "\n",
    "                #binarize \n",
    "                ret,thresh = cv2.threshold(crop1,127,255,cv2.THRESH_BINARY_INV)\n",
    "\n",
    "#                 cv2.waitKey(0)\n",
    "\n",
    "                #find contours\n",
    "                ctrs, new__ = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, \n",
    "                cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "                #sort contours\n",
    "                sorted_ctrs = sorted(ctrs, key=lambda ctr: cv2.boundingRect(ctr)[0])\n",
    "\n",
    "                for n, ctr in enumerate(sorted_ctrs):\n",
    "                    # Get bounding box\n",
    "                    x, y, w, h = cv2.boundingRect(ctr)\n",
    "\n",
    "                    if h>5:\n",
    "                        croped_image_label+=1\n",
    "                        character=crop1_copy[y-4:y+h+2,x-3:x+w+3]\n",
    "                        resized_char = cv2.resize(character, (32,32), interpolation = cv2.INTER_AREA)\n",
    "                        resized_char=255-resized_char\n",
    "                        cv2.imwrite('character/'+str(croped_image_label)+'.jpg',resized_char)\n",
    "                        cv2.waitKey(0)\n",
    "                        print(\"hjkhjk\")\n",
    "                \n",
    "                cv2.waitKey(0)\n",
    "                \n",
    "                croped_image_label+=1\n",
    "#                 cv2.imwrite('character/'+str(croped_image_label)+'.jpg',space)\n",
    "\n",
    "                \n",
    "######\n",
    "            if countn1!=0:\n",
    "                xp1=countp1\n",
    "                countn1=0\n",
    "\n",
    "    if countn!=0:\n",
    "        xp=countp\n",
    "        countn=0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\dell\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From C:\\Users\\dell\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\dell\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Nepali TExt:\n",
      "सर कलम ६ तर पर छ \n"
     ]
    }
   ],
   "source": [
    "########### final code ################\n",
    "from keras.models import load_model\n",
    "from keras_preprocessing.image import load_img, img_to_array\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "\n",
    "\n",
    "# load model\n",
    "model_path = 'final.h5'\n",
    "convnet = load_model(model_path)\n",
    "graph = tf.get_default_graph()\n",
    "\n",
    "# nep_numbers = ['o', '१' ,'२' , '३', '४', '५', '६', '७', '८', '९']\n",
    "# nep_dict={0:'p', '१':'s' ,'२':'s' , '३':'d', '४':'d', '५':'d', '६':'f', '७':'a', '८':'c', '९':'v'}\n",
    "# nepali=['ka','kha','ga','4','5','6','7','8','9','10','11','12','13','14','15','16','17','18','19','20','21','22','23','24','25','26','27','28','29','30','31','32','33','34','35','36','o', '१' ,'२' , '३', '४', '५', '६', '७', '८', '९']\n",
    "nepali={0:'ञ',1:'ट',2:'ठ',3:'ड',4:'ढ',5:'ण',6:'त',7:'थ',8:'द',9:'ध',10:'क',11:'न',12:'प',13:'फ',14:'ब',15:'भ',16:'म',17:'य',18:'र',19:'ल',20:'व',21:'ख',22:'श',23:'ष',24:'स',25:'ह',26:'क्ष',27:'त्र',28:'ज्ञ',29:'ग',30:'घ',31:'डo',32:'च',33:'छ',34:'ज',35:'झ',36:'o',37:'१' ,38:'२' ,39:'३',40:'४',41:'५',42:'६',43:'७',44:'८',45:'९'}\n",
    "def predict_character(image_file):\n",
    "    global graph\n",
    "    with graph.as_default():\n",
    "        image_loaded = load_img(image_file,target_size=(32,32),color_mode='grayscale')\n",
    "        img_arr = (img_to_array(image_loaded)/255.0).reshape(1,32,32,1)\n",
    "        probabilities = convnet.predict(img_arr)\n",
    "        pred = np.argmax(probabilities)\n",
    "#         print(pred)\n",
    "        return nepali[pred], np.amax(probabilities)\n",
    "\n",
    "##Horizontal Image segmentaion using projection method\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "word=[]\n",
    "text=\"\"\n",
    "\n",
    "# Load as greyscale\n",
    "im = cv2.imread('test_img/b3.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "space=cv2.imread('Space.jpg')\n",
    "(thresh, im) = cv2.threshold(im, 128, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "countp=0\n",
    "countn=0\n",
    "xp=0\n",
    "lower_y=0\n",
    "crop=0\n",
    "croped_image_label=0\n",
    "# Calculate horizontal projection\n",
    "proj = np.sum(im,1)\n",
    "\n",
    "for i in proj:\n",
    "    countp+=1\n",
    "    if i>(np.max(proj)-500):\n",
    "        lower_y=countp\n",
    "        countn=1\n",
    "\n",
    "    if (lower_y-xp)>1:\n",
    "        crop=im[xp-7:lower_y+4,0:im[1].size]\n",
    "#         print(\"first\")\n",
    "        \n",
    "\n",
    "        ## Vertical Image segmentaion using projection method\n",
    "        countp1=0\n",
    "        countn1=0\n",
    "        xp1=0\n",
    "        lower_y1=0\n",
    "        crop1=0\n",
    "        # Calculate vertical projection\n",
    "        proj1 = np.sum(crop,0)\n",
    "        #Calculating \n",
    "        height,width=crop.shape\n",
    "        for j in proj1:\n",
    "            countp1+=1\n",
    "\n",
    "            if j>(np.max(proj1)-5):\n",
    "                lower_y1=countp1\n",
    "                countn1=1\n",
    "            if (lower_y1-xp1)>1:\n",
    "                crop1=crop[0:height,xp1-3:lower_y1+3]\n",
    "                crop1_copy=np.copy(crop1)\n",
    "                \n",
    "#                 cv2.imshow(\"large\",crop1)\n",
    "\n",
    "                count=0\n",
    "                hori_black_sum=np.sum(crop1,1)\n",
    "                for k in hori_black_sum:\n",
    "                    min_acc=k<(np.min(hori_black_sum)+900)\n",
    "                    max_acc=k<(np.max(hori_black_sum)-900)\n",
    "                    count+=1\n",
    "                    if min_acc&max_acc:\n",
    "                        cv2.line(crop1, (0,count), (crop1[1].size,count), (255,0,0), 2)\n",
    "                        \n",
    "#                         print(\"krishna\")\n",
    "                        \n",
    "\n",
    "#                 cv2.imwrite('character.jpg',crop1)\n",
    "                ## segmentation of image\n",
    "                \n",
    "                #grayscale\n",
    "#                 gray = cv2.cvtColor(crop1,cv2.COLOR_BGR2GRAY)\n",
    "#                 cv2.waitKey(0)\n",
    "\n",
    "                #binarize \n",
    "                ret,thresh = cv2.threshold(crop1,127,255,cv2.THRESH_BINARY_INV)\n",
    "\n",
    "#                 cv2.waitKey(0)\n",
    "\n",
    "                #find contours\n",
    "                ctrs, new__ = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, \n",
    "                cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "                #sort contours\n",
    "                sorted_ctrs = sorted(ctrs, key=lambda ctr: cv2.boundingRect(ctr)[0])\n",
    "\n",
    "                for n, ctr in enumerate(sorted_ctrs):\n",
    "                    # Get bounding box\n",
    "                    x, y, w, h = cv2.boundingRect(ctr)\n",
    "\n",
    "                    if h>5:\n",
    "                        croped_image_label+=1\n",
    "                        character=crop1_copy[y-4:y+h+2,x-3:x+w+3]\n",
    "                        resized_char = cv2.resize(character, (32,32), interpolation = cv2.INTER_AREA)\n",
    "                        resized_char=255-resized_char\n",
    "                        cv2.imwrite('single_char/'+str(1)+'.jpg',resized_char)\n",
    "                        cv2.waitKey(0)\n",
    "#                         print(\"hjkhjk\")\n",
    "\n",
    "                        pre=predict_character('single_char/'+str(1)+'.jpg')[0]\n",
    "                        word.append(pre)\n",
    "                \n",
    "                cv2.waitKey(0)\n",
    "                \n",
    "                spc=\" \"\n",
    "                word.append(spc) \n",
    "                \n",
    "                croped_image_label+=1\n",
    "#                 cv2.imwrite('character/'+str(croped_image_label)+'.jpg',space)\n",
    "\n",
    "                \n",
    "######\n",
    "            if countn1!=0:\n",
    "                xp1=countp1\n",
    "                countn1=0\n",
    "\n",
    "    if countn!=0:\n",
    "        xp=countp\n",
    "        countn=0\n",
    "        \n",
    "\n",
    "# for i in range(1,56):\n",
    "# image = cv2.imread('test/'+str(1)+'.png')\n",
    "\n",
    "#     pre=predict_character('character/'+str(1)+'.jpg')[0]\n",
    "#     word.append(pre)\n",
    "# print(image)\n",
    "# print(word)\n",
    "print('Nepali TExt:')\n",
    "for j in word:\n",
    "    text+=j\n",
    "    \n",
    "print(text)\n",
    "\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
